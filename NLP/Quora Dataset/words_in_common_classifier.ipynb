{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from text_processor import TextProcessor\n",
    "from gensim.models.doc2vec import Doc2Vec\n",
    "import gensim\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from util import get_balanced_data\n",
    "from word2vec import Word2Vec\n",
    "from adversarial_algos import adversarial_white_box_change\n",
    "from word_in_common_feature_extractor import WordsInCommonFeatureExtractor\n",
    "from model import Model\n",
    "\n",
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "pal = sns.color_palette()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from text_processor import TextProcessor\n",
    "from gensim.models.doc2vec import Doc2Vec\n",
    "import gensim\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from util import get_balanced_data\n",
    "from word2vec import Word2Vec\n",
    "from adversarial_algos import adversarial_white_box_change\n",
    "from word_in_common_feature_extractor import WordsInCommonFeatureExtractor\n",
    "from model import Model\n",
    "\n",
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "pal = sns.color_palette()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 298526 positive samples\n",
      "We have 298526 negative samples\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = get_balanced_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = TextProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = WordsInCommonFeatureExtractor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(feature_extractor, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(238820, 1)\n",
      "CPU times: user 49.3 s, sys: 672 ms, total: 49.9 s\n",
      "Wall time: 48.2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6009684468560947"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_bin = [0 if y < 0.38 else 1 for y in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7120389910561753"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred_bin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 39.8 s, sys: 3.49 s, total: 43.3 s\n",
      "Wall time: 43.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "w2v = Word2Vec()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adversarial White Box Algorithm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial q1: Who is the richest gambler of all time and how can I reach his level?\n",
      "initial q2: Who is the richest gambler of all time and how can I reach his level as a gambler?\n",
      "Initial similarity is [0.95007377]\n",
      "\n",
      "q1: 'Who is the richest gambler of all time and how can I reach his level?'\n",
      "q2: 'Who is the wealthiest gambler of all time and how can I reach his level as a gambler?'\n",
      "Replacing 1 words we have a similarity of [0.70878911]\n",
      "\n",
      "q1: 'Who is the richest gambler of all time and how can I reach his level?'\n",
      "q2: 'Who is the wealthiest gambler of all day and how can I reach his level as a gambler?'\n",
      "Replacing 2 words we have a similarity of [0.52782562]\n",
      "\n",
      "q1: 'Who is the richest gambler of all time and how can I reach his level?'\n",
      "q2: 'Who is the wealthiest gambler of all day and how can I reaching his level as a gambler?'\n",
      "Replacing 3 words we have a similarity of [0.38707624]\n"
     ]
    }
   ],
   "source": [
    "q1 = 'Who is the richest gambler of all time and how can I reach his level?'\n",
    "q2 = 'Who is the richest gambler of all time and how can I reach his level as a gambler?'\n",
    "\n",
    "adversarial_white_box_change(q1, q2, model, tp, w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial q1: How does the HP OfficeJet 4620 Airprint compare to the HP DesignJet Z3200 24-in PostScript Photo Printer?\n",
      "initial q2: How does the HP OfficeJet 4620 Airprint compare to the HP DesignJet T1530 36-in PostScript Printer?\n",
      "Initial similarity is [0.64846795]\n",
      "\n",
      "q1: 'How does the HP OfficeJet 4620 Airprint compare to the HP DesignJet Z3200 24-in PostScript Photo Printer?'\n",
      "q2: 'How does the HP OfficeJet 4620 Airprint comparing to the HP DesignJet T1530 36-in PostScript Printer?'\n",
      "Replacing 1 words we have a similarity of [0.5559755]\n",
      "\n",
      "q1: 'How does the HP OfficeJet 4620 Airprint compare to the HP DesignJet Z3200 24-in PostScript Photo Printer?'\n",
      "q2: 'How does the HP OfficeJet 4620 Airprint comparing to the HP DesignJet T1530 36-in Adobe_PostScript Printer?'\n",
      "Replacing 2 words we have a similarity of [0.4750446]\n",
      "\n",
      "q1: 'How does the HP OfficeJet 4620 Airprint compare to the HP DesignJet Z3200 24-in PostScript Photo Printer?'\n",
      "q2: 'How does the Hewlett_Packard OfficeJet 4620 Airprint comparing to the HP DesignJet T1530 36-in Adobe_PostScript Printer?'\n",
      "Replacing 3 words we have a similarity of [0.45331124]\n",
      "\n",
      "q1: 'How does the HP OfficeJet 4620 Airprint compare to the HP DesignJet Z3200 24-in PostScript Photo Printer?'\n",
      "q2: 'How does the Hewlett_Packard OfficeJet 4620 Airprint comparing to the Hewlett_Packard DesignJet T1530 36-in Adobe_PostScript Printer?'\n",
      "Replacing 4 words we have a similarity of [0.40363499]\n",
      "\n",
      "q1: 'How does the HP OfficeJet 4620 Airprint compare to the HP DesignJet Z3200 24-in PostScript Photo Printer?'\n",
      "q2: 'How does the Hewlett_Packard_Co. OfficeJet 4620 Airprint comparing to the Hewlett_Packard DesignJet T1530 36-in Adobe_PostScript Printer?'\n",
      "Replacing 5 words we have a similarity of [0.38707624]\n",
      "\n",
      "initial q1: What is induction hardening? Where it is used?\n",
      "initial q2: What is induction hardening?\n",
      "Initial similarity is [0.7389497]\n",
      "\n",
      "q1: 'What is induction hardening? Where it is used?'\n",
      "q2: 'What is induction harden?'\n",
      "Replacing 1 words we have a similarity of [0.44337599]\n",
      "UNSUCCESSFULL\n",
      "\n",
      "initial q1: Where can I buy cheap t-shirts?\n",
      "initial q2: Where can I buy cheap wholesale t-shirts?\n",
      "Initial similarity is [0.78117451]\n",
      "\n",
      "q1: 'Where can I buy cheap t-shirts?'\n",
      "q2: 'Where can I sell cheap wholesale t-shirts?'\n",
      "Replacing 1 words we have a similarity of [0.52782562]\n",
      "\n",
      "q1: 'Where can I buy cheap t-shirts?'\n",
      "q2: 'Where could I sell cheap wholesale t-shirts?'\n",
      "Replacing 2 words we have a similarity of [0.46750446]\n",
      "UNSUCCESSFULL\n",
      "\n",
      "initial q1: How do I get the PAN card?\n",
      "initial q2: How can I get an urgent PAN card no?\n",
      "Initial similarity is [0.78117451]\n",
      "\n",
      "q1: 'How do I get the PAN card?'\n",
      "q2: 'How can I getting an urgent PAN card no?'\n",
      "Replacing 1 words we have a similarity of [0.52782562]\n",
      "\n",
      "q1: 'How do I get the PAN card?'\n",
      "q2: 'How can I getting an urgent Partido_Acción_Nacional card no?'\n",
      "Replacing 2 words we have a similarity of [0.34686213]\n",
      "\n",
      "initial q1: Why does a woman love a man?\n",
      "initial q2: When does a woman love a man?\n",
      "Initial similarity is [0.95007377]\n",
      "\n",
      "q1: 'Why does a woman love a man?'\n",
      "q2: 'When does a woman loved a man?'\n",
      "Replacing 1 words we have a similarity of [0.61227525]\n",
      "\n",
      "q1: 'Why does a woman love a man?'\n",
      "q2: 'When does a man loved a man?'\n",
      "Replacing 2 words we have a similarity of [0.44337599]\n",
      "UNSUCCESSFULL\n",
      "\n",
      "initial q1: Who is the poorest professor in any of the IITs?\n",
      "initial q2: Who is the richest professor in any of the IITs?\n",
      "Initial similarity is [0.61227525]\n",
      "\n",
      "q1: 'Who is the poorest professor in any of the IITs?'\n",
      "q2: 'Who is the richest associate_professor in any of the IITs?'\n",
      "Replacing 1 words we have a similarity of [0.38707624]\n",
      "\n",
      "initial q1: How can the new user experience of Twitter be improved in 2016?\n",
      "initial q2: How can the new user experience of Twitter be improved?\n",
      "Initial similarity is [0.82943144]\n",
      "\n",
      "q1: 'How can the new user experience of Twitter be improved in 2016?'\n",
      "q2: 'How can the revamped user experience of Twitter be improved?'\n",
      "Replacing 1 words we have a similarity of [0.63338766]\n",
      "\n",
      "q1: 'How can the new user experience of Twitter be improved in 2016?'\n",
      "q2: 'How can the revamped users experience of Twitter be improved?'\n",
      "Replacing 2 words we have a similarity of [0.48090916]\n",
      "\n",
      "q1: 'How can the new user experience of Twitter be improved in 2016?'\n",
      "q2: 'How can the revamped users experiences of Twitter be improved?'\n",
      "Replacing 3 words we have a similarity of [0.35892636]\n",
      "\n",
      "initial q1: What is the meaning of below sentence?\n",
      "initial q2: What is the meaning of this sentence?\n",
      "Initial similarity is [0.95007377]\n",
      "\n",
      "q1: 'What is the meaning of below sentence?'\n",
      "q2: 'What is the meanings of this sentence?'\n",
      "Replacing 1 words we have a similarity of [0.52782562]\n",
      "\n",
      "q1: 'What is the meaning of below sentence?'\n",
      "q2: 'What is the meanings of this sentences?'\n",
      "Replacing 2 words we have a similarity of [0.27447673]\n",
      "\n",
      "initial q1: How do cottontail rabbits adapt to their environment?\n",
      "initial q2: Where do cottontail rabbits live? How do they adapt to their environment?\n",
      "Initial similarity is [0.80932439]\n",
      "\n",
      "q1: 'How do cottontail rabbits adapt to their environment?'\n",
      "q2: 'Where do cottontails rabbits live? How do they adapt to their environment?'\n",
      "Replacing 1 words we have a similarity of [0.58814679]\n",
      "\n",
      "q1: 'How do cottontail rabbits adapt to their environment?'\n",
      "q2: 'Where do cottontails rabbit live? How do they adapt to their environment?'\n",
      "Replacing 2 words we have a similarity of [0.42226358]\n",
      "\n",
      "q1: 'How do cottontail rabbits adapt to their environment?'\n",
      "q2: 'Where do cottontails rabbit live? How do they adapting to their environment?'\n",
      "Replacing 3 words we have a similarity of [0.29324332]\n",
      "\n",
      "initial q1: What are the Keys to the Kingdom?\n",
      "initial q2: What are the keys to the kingdom of contentment?\n",
      "Initial similarity is [0.7389497]\n",
      "\n",
      "q1: 'What are the Keys to the Kingdom?'\n",
      "q2: 'What are the passkey to the kingdom of contentment?'\n",
      "Replacing 1 words we have a similarity of [0.44337599]\n",
      "UNSUCCESSFULL\n",
      "\n",
      "initial q1: How do I transfer to another college?\n",
      "initial q2: How can one transfer to another college?\n",
      "Initial similarity is [0.78117451]\n",
      "\n",
      "q1: 'How do I transfer to another college?'\n",
      "q2: 'How can one transfers to another college?'\n",
      "Replacing 1 words we have a similarity of [0.52782562]\n",
      "\n",
      "q1: 'How do I transfer to another college?'\n",
      "q2: 'How can one transfers to another colleges?'\n",
      "Replacing 2 words we have a similarity of [0.34686213]\n",
      "\n",
      "initial q1: What type of government does Guatemala have? How does it compare to the one in Canada?\n",
      "initial q2: What type of government does Guatemala have? How does it compare to the one in Italy?\n",
      "Initial similarity is [0.7389497]\n",
      "\n",
      "q1: 'What type of government does Guatemala have? How does it compare to the one in Canada?'\n",
      "q2: 'What kind of government does Guatemala have? How does it compare to the one in Italy?'\n",
      "Replacing 1 words we have a similarity of [0.57474208]\n",
      "\n",
      "q1: 'What type of government does Guatemala have? How does it compare to the one in Canada?'\n",
      "q2: 'What kind of government does El_Salvador have? How does it compare to the one in Italy?'\n",
      "Replacing 2 words we have a similarity of [0.44337599]\n",
      "\n",
      "q1: 'What type of government does Guatemala have? How does it compare to the one in Canada?'\n",
      "q2: 'What kind of government does El_Salvador have? How does it comparing to the one in Italy?'\n",
      "Replacing 3 words we have a similarity of [0.33589464]\n",
      "\n",
      "initial q1: Which games I can play on Intel i3 (2nd Gen) 2GB RAM with HD 3000 Graphics?\n",
      "initial q2: Which games I can play on Intel i3 (5th Gen) 4GB RAM with HD 5500 Graphics?\n",
      "Initial similarity is [0.65201625]\n",
      "\n",
      "q1: 'Which games I can play on Intel i3 (2nd Gen) 2GB RAM with HD 3000 Graphics?'\n",
      "q2: 'Which game I can play on Intel i3 (5th Gen) 4GB RAM with HD 5500 Graphics?'\n",
      "Replacing 1 words we have a similarity of [0.57474208]\n",
      "\n",
      "q1: 'Which games I can play on Intel i3 (2nd Gen) 2GB RAM with HD 3000 Graphics?'\n",
      "q2: 'Which game I can playing on Intel i3 (5th Gen) 4GB RAM with HD 5500 Graphics?'\n",
      "Replacing 2 words we have a similarity of [0.50560203]\n",
      "\n",
      "q1: 'Which games I can play on Intel i3 (2nd Gen) 2GB RAM with HD 3000 Graphics?'\n",
      "q2: 'Which game I can playing on Nvidia i3 (5th Gen) 4GB RAM with HD 5500 Graphics?'\n",
      "Replacing 3 words we have a similarity of [0.44337599]\n",
      "\n",
      "q1: 'Which games I can play on Intel i3 (2nd Gen) 2GB RAM with HD 3000 Graphics?'\n",
      "q2: 'Which game I can playing on Nvidia Elfed_Thomas (5th Gen) 4GB RAM with HD 5500 Graphics?'\n",
      "Replacing 4 words we have a similarity of [0.38707624]\n",
      "\n",
      "initial q1: Is there life on Mars?\n",
      "initial q2: Is life possible in Mars?\n",
      "Initial similarity is [0.7389497]\n",
      "\n",
      "q1: 'Is there life on Mars?'\n",
      "q2: 'Is lives possible in Mars?'\n",
      "Replacing 1 words we have a similarity of [0.44337599]\n",
      "\n",
      "q1: 'Is there life on Mars?'\n",
      "q2: 'Is lives possible in Red_Planet?'\n",
      "Replacing 2 words we have a similarity of [0.24632686]\n",
      "\n",
      "initial q1: What does it feel like to have a miscarriage?\n",
      "initial q2: What is it like to have a miscarriage?\n",
      "Initial similarity is [0.7389497]\n",
      "\n",
      "q1: 'What does it feel like to have a miscarriage?'\n",
      "q2: 'What is it really to have a miscarriage?'\n",
      "Replacing 1 words we have a similarity of [0.44337599]\n",
      "\n",
      "q1: 'What does it feel like to have a miscarriage?'\n",
      "q2: 'What is it really to have a miscarriages?'\n",
      "Replacing 2 words we have a similarity of [0.24632686]\n",
      "\n",
      "initial q1: How do the Jews perceive, feel, understand, view, believe, and opine, about the Dalits, Shudras, and Dasa?\n",
      "initial q2: How do the Nepalese perceive, feel, understand, view, believe, and/or opine, about Dalits, Shudras, and Dasa?\n",
      "Initial similarity is [0.76911028]\n",
      "\n",
      "q1: 'How do the Jews perceive, feel, understand, view, believe, and opine, about the Dalits, Shudras, and Dasa?'\n",
      "q2: 'How do the Nepalese perceived, feel, understand, view, believe, and/or opine, about Dalits, Shudras, and Dasa?'\n",
      "Replacing 1 words we have a similarity of [0.668575]\n",
      "\n",
      "q1: 'How do the Jews perceive, feel, understand, view, believe, and opine, about the Dalits, Shudras, and Dasa?'\n",
      "q2: 'How do the Nepalese perceived, feeling, understand, view, believe, and/or opine, about Dalits, Shudras, and Dasa?'\n",
      "Replacing 2 words we have a similarity of [0.58060664]\n",
      "\n",
      "q1: 'How do the Jews perceive, feel, understand, view, believe, and opine, about the Dalits, Shudras, and Dasa?'\n",
      "q2: 'How do the Nepalese perceived, feeling, comprehend, view, believe, and/or opine, about Dalits, Shudras, and Dasa?'\n",
      "Replacing 3 words we have a similarity of [0.5029875]\n",
      "\n",
      "q1: 'How do the Jews perceive, feel, understand, view, believe, and opine, about the Dalits, Shudras, and Dasa?'\n",
      "q2: 'How do the Nepalese perceived, feeling, comprehend, views, believe, and/or opine, about Dalits, Shudras, and Dasa?'\n",
      "Replacing 4 words we have a similarity of [0.4339927]\n",
      "\n",
      "q1: 'How do the Jews perceive, feel, understand, view, believe, and opine, about the Dalits, Shudras, and Dasa?'\n",
      "q2: 'How do the Nepalese perceived, feeling, comprehend, views, say, and/or opine, about Dalits, Shudras, and Dasa?'\n",
      "Replacing 5 words we have a similarity of [0.37226051]\n",
      "\n",
      "q1: 'How do the Jews perceive, feel, understand, view, believe, and opine, about the Dalits, Shudras, and Dasa?'\n",
      "q2: 'How do the Nepalese perceived, feeling, comprehend, views, say, and/or opining, about Dalits, Shudras, and Dasa?'\n",
      "Replacing 6 words we have a similarity of [0.31670155]\n",
      "\n",
      "q1: 'How do the Jews perceive, feel, understand, view, believe, and opine, about the Dalits, Shudras, and Dasa?'\n",
      "q2: 'How do the Nepalese perceived, feeling, comprehend, views, say, and/or opining, about Dalits, Sudras, and Dasa?'\n",
      "Replacing 7 words we have a similarity of [0.26643391]\n",
      "\n",
      "q1: 'How do the Jews perceive, feel, understand, view, believe, and opine, about the Dalits, Shudras, and Dasa?'\n",
      "q2: 'How do the Nepalese perceived, feeling, comprehend, views, say, and/or opining, about Dalits, Sudras, and Samsthan?'\n",
      "Replacing 8 words we have a similarity of [0.22073606]\n",
      "\n",
      "q1: 'How do the Jews perceive, feel, understand, view, believe, and opine, about the Dalits, Shudras, and Dasa?'\n",
      "q2: 'How want the Nepalese perceived, feeling, comprehend, views, say, and/or opining, about Dalits, Sudras, and Samsthan?'\n",
      "Replacing 9 words we have a similarity of [0.21572916]\n",
      "\n",
      "q1: 'How do the Jews perceive, feel, understand, view, believe, and opine, about the Dalits, Shudras, and Dasa?'\n",
      "q2: 'How want the Nepalese perceived, feeling, comprehend, views, say, and/or opining, abut Dalits, Sudras, and Samsthan?'\n",
      "Replacing 10 words we have a similarity of [0.21113951]\n",
      "\n",
      "initial q1: How do you form an LLC in Florida?\n",
      "initial q2: How do I form an LLC?\n",
      "Initial similarity is [0.7389497]\n",
      "\n",
      "q1: 'How do you form an LLC in Florida?'\n",
      "q2: 'How do I forms an LLC?'\n",
      "Replacing 1 words we have a similarity of [0.44337599]\n",
      "\n",
      "q1: 'How do you form an LLC in Florida?'\n",
      "q2: 'How do I forms an Partners_LLC?'\n",
      "Replacing 2 words we have a similarity of [0.24632686]\n",
      "\n",
      "initial q1: What are some interesting areas of biochemistry that I could do undergraduate honors thesis in?\n",
      "initial q2: What are some interesting areas of architecture that I could do undergraduate honors thesis in?\n",
      "Initial similarity is [0.76240793]\n",
      "\n",
      "q1: 'What are some interesting areas of biochemistry that I could do undergraduate honors thesis in?'\n",
      "q2: 'What are some intriguing areas of architecture that I could do undergraduate honors thesis in?'\n",
      "Replacing 1 words we have a similarity of [0.61227525]\n",
      "\n",
      "q1: 'What are some interesting areas of biochemistry that I could do undergraduate honors thesis in?'\n",
      "q2: 'What are some intriguing regions of architecture that I could do undergraduate honors thesis in?'\n",
      "Replacing 2 words we have a similarity of [0.48943943]\n",
      "\n",
      "q1: 'What are some interesting areas of biochemistry that I could do undergraduate honors thesis in?'\n",
      "q2: 'What are some intriguing regions of architecture that I would do undergraduate honors thesis in?'\n",
      "Replacing 3 words we have a similarity of [0.38707624]\n",
      "\n",
      "initial q1: How does an HVAC chiller work?\n",
      "initial q2: How do HVAC chillers work?\n",
      "Initial similarity is [0.61227525]\n",
      "\n",
      "q1: 'How does an HVAC chiller work?'\n",
      "q2: 'How do heating_ventilation chillers work?'\n",
      "Replacing 1 words we have a similarity of [0.38707624]\n",
      "\n",
      "initial q1: How can I increase my website traffic? (I am running some retail online stores)\n",
      "initial q2: How can I increase traffic to my website? (I am running several retail online stores)\n",
      "Initial similarity is [0.87330138]\n",
      "\n",
      "q1: 'How can I increase my website traffic? (I am running some retail online stores )'\n",
      "q2: 'How can I decrease traffic to my website? (I am running several retail online stores )'\n",
      "Replacing 1 words we have a similarity of [0.7389497]\n",
      "\n",
      "q1: 'How can I increase my website traffic? (I am running some retail online stores )'\n",
      "q2: 'How can I decrease traffic to my Web_site? (I am running several retail online stores )'\n",
      "Replacing 2 words we have a similarity of [0.6252675]\n",
      "\n",
      "q1: 'How can I increase my website traffic? (I am running some retail online stores )'\n",
      "q2: 'How can I decrease traffic to my Web_site? (I am running several retailing online stores )'\n",
      "Replacing 3 words we have a similarity of [0.52782562]\n",
      "\n",
      "q1: 'How can I increase my website traffic? (I am running some retail online stores )'\n",
      "q2: 'How can I decrease traffic to my Web_site? (I am running several retailing Internet stores )'\n",
      "Replacing 4 words we have a similarity of [0.44337599]\n",
      "\n",
      "q1: 'How can I increase my website traffic? (I am running some retail online stores )'\n",
      "q2: 'How can I decrease traffic to my Web_site? (I am running several retailing Internet store )'\n",
      "Replacing 5 words we have a similarity of [0.36948257]\n",
      "\n",
      "q1: 'How can I increase my website traffic? (I am running some retail online stores )'\n",
      "q2: 'How could I decrease traffic to my Web_site? (I am running several retailing Internet store )'\n",
      "Replacing 6 words we have a similarity of [0.35395874]\n",
      "\n",
      "q1: 'How can I increase my website traffic? (I am running some retail online stores )'\n",
      "q2: 'How could I decrease traffic to my Web_site? (I'm running several retailing Internet store )'\n",
      "Replacing 7 words we have a similarity of [0.34015978]\n",
      "\n",
      "initial q1: Friends or family who is more important?\n",
      "initial q2: Who is more important, friends or family?\n",
      "Initial similarity is [0.78117451]\n",
      "\n",
      "q1: 'Friends or family who is more important?'\n",
      "q2: 'Who is more vitally_important, friends or family?'\n",
      "Replacing 1 words we have a similarity of [0.52782562]\n",
      "\n",
      "q1: 'Friends or family who is more important?'\n",
      "q2: 'Who is more vitally_important, acquaintances or family?'\n",
      "Replacing 2 words we have a similarity of [0.34686213]\n",
      "\n",
      "initial q1: What is the most amazing thing have you done with your life?\n",
      "initial q2: What is the most amazing thing about life?\n",
      "Initial similarity is [0.78117451]\n",
      "\n",
      "q1: 'What is the most amazing thing have you done with your life?'\n",
      "q2: 'What is the most incredible thing about life?'\n",
      "Replacing 1 words we have a similarity of [0.52782562]\n",
      "\n",
      "q1: 'What is the most amazing thing have you done with your life?'\n",
      "q2: 'What is the most incredible things about life?'\n",
      "Replacing 2 words we have a similarity of [0.34686213]\n",
      "\n",
      "initial q1: Is there a character limit to answers on Quora?\n",
      "initial q2: Is there a character limit to questions on Quora? \n",
      "Initial similarity is [0.668575]\n",
      "\n",
      "q1: 'Is there a character limit to answers on Quora?'\n",
      "q2: 'Is there a characters limit to questions on Quora?'\n",
      "Replacing 1 words we have a similarity of [0.46750446]\n",
      "\n",
      "q1: 'Is there a character limit to answers on Quora?'\n",
      "q2: 'Is there a characters limits to questions on Quora?'\n",
      "Replacing 2 words we have a similarity of [0.31670155]\n",
      "\n",
      "initial q1: What do people from other countries think of America and Americans?\n",
      "initial q2: What do people think of Americans?\n",
      "Initial similarity is [0.668575]\n",
      "\n",
      "q1: 'What do people from other countries think of America and Americans?'\n",
      "q2: 'What do peole think of Americans?'\n",
      "Replacing 1 words we have a similarity of [0.46750446]\n",
      "\n",
      "q1: 'What do people from other countries think of America and Americans?'\n",
      "q2: 'What do peole know of Americans?'\n",
      "Replacing 2 words we have a similarity of [0.31670155]\n",
      "\n",
      "initial q1: What are examples of animals that live in the desert?\n",
      "initial q2: What are the types of animals that live in a desert?\n",
      "Initial similarity is [0.668575]\n",
      "\n",
      "q1: 'What are examples of animals that live in the desert?'\n",
      "q2: 'What are the types of animal that live in a desert?'\n",
      "Replacing 1 words we have a similarity of [0.46750446]\n",
      "\n",
      "q1: 'What are examples of animals that live in the desert?'\n",
      "q2: 'What are the types of animal that living in a desert?'\n",
      "Replacing 2 words we have a similarity of [0.31670155]\n",
      "\n",
      "initial q1: Do any airports have heated runways?\n",
      "initial q2: Are there any airports with heated runways?\n",
      "Initial similarity is [0.95007377]\n",
      "\n",
      "q1: 'Do any airports have heated runways?'\n",
      "q2: 'Are there any airports with heated runway?'\n",
      "Replacing 1 words we have a similarity of [0.61227525]\n",
      "\n",
      "q1: 'Do any airports have heated runways?'\n",
      "q2: 'Are there'sa any airports with heated runway?'\n",
      "Replacing 2 words we have a similarity of [0.52782562]\n",
      "\n",
      "q1: 'Do any airports have heated runways?'\n",
      "q2: 'Are there'sa whatsoever airports with heated runway?'\n",
      "Replacing 3 words we have a similarity of [0.46750446]\n",
      "\n",
      "q1: 'Do any airports have heated runways?'\n",
      "q2: 'Are there'sa whatsoever airports wtih heated runway?'\n",
      "Replacing 4 words we have a similarity of [0.42226358]\n",
      "UNSUCCESSFULL\n",
      "\n",
      "initial q1: What is the cure for Dry eyes disease?\n",
      "initial q2: What is the cure for dry eyes?\n",
      "Initial similarity is [0.78117451]\n",
      "\n",
      "q1: 'What is the cure for Dry eyes disease?'\n",
      "q2: 'What is the cures for dry eyes?'\n",
      "Replacing 1 words we have a similarity of [0.52782562]\n",
      "\n",
      "q1: 'What is the cure for Dry eyes disease?'\n",
      "q2: 'What is the cures for wet eyes?'\n",
      "Replacing 2 words we have a similarity of [0.34686213]\n",
      "\n",
      "initial q1: What color is red?\n",
      "initial q2: What does the color red represent?\n",
      "Initial similarity is [0.7389497]\n",
      "\n",
      "q1: 'What color is red?'\n",
      "q2: 'What does the colors red represent?'\n",
      "Replacing 1 words we have a similarity of [0.44337599]\n",
      "\n",
      "q1: 'What color is red?'\n",
      "q2: 'What does the colors yellow represent?'\n",
      "Replacing 2 words we have a similarity of [0.24632686]\n",
      "\n",
      "initial q1: What are the online part time jobs in India?\n",
      "initial q2: Which is the best online part time job in India?\n",
      "Initial similarity is [0.63338766]\n",
      "\n",
      "q1: 'What are the online part time jobs in India?'\n",
      "q2: 'Which is the best Internet part time job in India?'\n",
      "Replacing 1 words we have a similarity of [0.48090916]\n",
      "\n",
      "q1: 'What are the online part time jobs in India?'\n",
      "q2: 'Which is the best Internet integral_part time job in India?'\n",
      "Replacing 2 words we have a similarity of [0.35892636]\n",
      "\n",
      "initial q1: Why was the Battle of Wounded Knee fought? Who won the war?\n",
      "initial q2: Why was the Battle of Wounded Knee fought?\n",
      "Initial similarity is [0.80932439]\n",
      "\n",
      "q1: 'Why was the Battle of Wounded Knee fought? Who won the war?'\n",
      "q2: 'Why was the Battles of Wounded Knee fought?'\n",
      "Replacing 1 words we have a similarity of [0.58814679]\n",
      "\n",
      "q1: 'Why was the Battle of Wounded Knee fought? Who won the war?'\n",
      "q2: 'Why was the Battles of Injured Knee fought?'\n",
      "Replacing 2 words we have a similarity of [0.42226358]\n",
      "\n",
      "q1: 'Why was the Battle of Wounded Knee fought? Who won the war?'\n",
      "q2: 'Why was the Battles of Injured Ankle fought?'\n",
      "Replacing 3 words we have a similarity of [0.29324332]\n",
      "\n",
      "initial q1: What would be painted on medieval armor?\n",
      "initial q2: Was Medieval armor painted?\n",
      "Initial similarity is [0.78117451]\n",
      "\n",
      "q1: 'What would be painted on medieval armor?'\n",
      "q2: 'Was Medieval armors painted?'\n",
      "Replacing 1 words we have a similarity of [0.52782562]\n",
      "\n",
      "q1: 'What would be painted on medieval armor?'\n",
      "q2: 'Was Medieval armors repainted?'\n",
      "Replacing 2 words we have a similarity of [0.34686213]\n",
      "\n",
      "initial q1: Who was Jesus and why was he born?\n",
      "initial q2: When was Jesus born?\n",
      "Initial similarity is [0.95007377]\n",
      "\n",
      "q1: 'Who was Jesus and why was he born?'\n",
      "q2: 'When was Jesus_Christ born?'\n",
      "Replacing 1 words we have a similarity of [0.52782562]\n",
      "UNSUCCESSFULL\n",
      "\n",
      "initial q1: What basically is big data?\n",
      "initial q2: What is big data? What is it used for?\n",
      "Initial similarity is [0.61227525]\n",
      "\n",
      "q1: 'What basically is big data?'\n",
      "q2: 'What is huge data? What is it used for?'\n",
      "Replacing 1 words we have a similarity of [0.38707624]\n",
      "\n",
      "initial q1: What caused the Big Bang?\n",
      "initial q2: Which elements collision caused big bang?\n",
      "Initial similarity is [0.668575]\n",
      "\n",
      "q1: 'What caused the Big Bang?'\n",
      "q2: 'Which elements collision causing big bang?'\n",
      "Replacing 1 words we have a similarity of [0.46750446]\n",
      "\n",
      "q1: 'What caused the Big Bang?'\n",
      "q2: 'Which elements collision causing huge bang?'\n",
      "Replacing 2 words we have a similarity of [0.31670155]\n",
      "\n",
      "initial q1: What is the difference between a psychologist and a psychiatrist?”?\n",
      "initial q2: What's the difference between psychiatrist and psychologist?\n",
      "Initial similarity is [0.668575]\n",
      "\n",
      "q1: 'What is the difference between a psychologist and a psychiatrist? ”?'\n",
      "q2: 'What's the disparity between psychiatrist and psychologist?'\n",
      "Replacing 1 words we have a similarity of [0.46750446]\n",
      "\n",
      "q1: 'What is the difference between a psychologist and a psychiatrist? ”?'\n",
      "q2: 'What's the disparity between psychiatrist and clinical_psychologist?'\n",
      "Replacing 2 words we have a similarity of [0.31670155]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    q1 = X_test[i, 0]\n",
    "    q2 = X_test[i, 1]\n",
    "    q1_tokenized = tp.tokenize(q1)\n",
    "    q2_tokenized = tp.tokenize(q2)\n",
    "    if model.predict_single(q1, q2) > 0.6:\n",
    "        adversarial_white_box_change(q1, q2, model, tp, w2v)\n",
    "        print()\n",
    "#         print(i)\n",
    "#         print(q1)\n",
    "#         print(q2)\n",
    "#         print\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
