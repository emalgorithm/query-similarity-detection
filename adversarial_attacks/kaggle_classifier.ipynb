{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from util import get_balanced_data\n",
    "from word2vec import Word2Vec\n",
    "from glove_synonyms import GloveSynonyms\n",
    "from adversarial_algos import adversarial_white_box_change\n",
    "from kaggle_model import KaggleModel\n",
    "from text_processor import TextProcessor\n",
    "\n",
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KaggleModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.7850677]], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_single('How good is los angeles?', 'How great is los angeles?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 298526 positive samples\n",
      "We have 298526 negative samples\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = get_balanced_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Glove Model\n",
      "Done. 65713  words loaded!\n"
     ]
    }
   ],
   "source": [
    "glove = GloveSynonyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = TextProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['inclement', 'mala', 'naughty', 'rotten', 'amiss']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove.most_similar('bad', n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial q1: What is it like being in a relationship with a sociopath?\n",
      "initial q2: What does it feel like to be in a relationship with a sociopath?\n",
      "Initial similarity is [[0.65208316]]\n",
      "\n",
      "q1: 'What is it like being in a relationship with a sociopath?'\n",
      "q2: 'What does it feel like to be in una relationship with a sociopath?'\n",
      "Similarity: [[0.4337341]]. Replaced words ['a'] with ['una']\n",
      "\n",
      "initial q1: How can I gain weight within month?\n",
      "initial q2: How do I gain weight within a month?\n",
      "Initial similarity is [[0.8393157]]\n",
      "\n",
      "q1: 'How can I gain weight within month?'\n",
      "q2: 'How do I gain weight within a months?'\n",
      "Similarity: [[0.55743736]]. Replaced words ['month'] with ['months']\n",
      "\n",
      "q1: 'How can I gain weight within month?'\n",
      "q2: 'How do I gain weigh within a months?'\n",
      "Similarity: [[0.443016]]. Replaced words ['month', 'weight'] with ['months', 'weigh']\n",
      "\n",
      "initial q1: How can I start to learn robotics from zero?\n",
      "initial q2: What is the best way to start learning robotics by self from the very basics and zero level?\n",
      "Initial similarity is [[0.73351014]]\n",
      "\n",
      "q1: 'How can I start to learn robotics from zero?'\n",
      "q2: 'What is du best way to start learning robotics by self from the very basics and zero level?'\n",
      "Similarity: [[0.31475976]]. Replaced words ['the'] with ['du']\n",
      "\n",
      "initial q1: How can I curate my Quora feed?\n",
      "initial q2: How do I personalize my Quora feed?\n",
      "Initial similarity is [[0.61236167]]\n",
      "UNSUCCESSFULL\n",
      "\n",
      "initial q1: What are the causes and types of diabetes?\n",
      "initial q2: What are the types of diabetes and what causes diabetes?\n",
      "Initial similarity is [[0.8763225]]\n",
      "\n",
      "q1: 'What are the causes and types of diabetes?'\n",
      "q2: 'What are the types of diabetes and quel causes diabetes?'\n",
      "Similarity: [[0.44292322]]. Replaced words ['what'] with ['quel']\n",
      "\n",
      "initial q1: How can I backup my phone data?\n",
      "initial q2: How do I backup my phone?\n",
      "Initial similarity is [[0.6590034]]\n",
      "\n",
      "q1: 'How can I backup my phone data?'\n",
      "q2: 'How do I backups my phone?'\n",
      "Similarity: [[0.54522485]]. Replaced words ['backup'] with ['backups']\n",
      "\n",
      "q1: 'How can I backup my phone data?'\n",
      "q2: 'How do I backups my telephones?'\n",
      "Similarity: [[0.54320395]]. Replaced words ['backup', 'phone'] with ['backups', 'telephones']\n",
      "UNSUCCESSFULL\n",
      "\n",
      "initial q1: How can Facebook and Twitter make money for you?\n",
      "initial q2: How do I make money on Facebook?\n",
      "Initial similarity is [[0.631886]]\n",
      "\n",
      "q1: 'How can Facebook and Twitter make money for you?'\n",
      "q2: 'How do I make money orn Facebook?'\n",
      "Similarity: [[0.5827347]]. Replaced words ['on'] with ['orn']\n",
      "\n",
      "q1: 'How can Facebook and Twitter make money for you?'\n",
      "q2: 'How doing I make money orn Facebook?'\n",
      "Similarity: [[0.5770568]]. Replaced words ['on', 'do'] with ['orn', 'doing']\n",
      "\n",
      "q1: 'How can Facebook and Twitter make money for you?'\n",
      "q2: 'How done I make money orn Facebook?'\n",
      "Similarity: [[0.54788136]]. Replaced words ['on', 'do', 'doing'] with ['orn', 'doing', 'done']\n",
      "\n",
      "q1: 'How can Facebook and Twitter make money for you?'\n",
      "q2: 'How done I deliver money orn Facebook?'\n",
      "Similarity: [[0.5134336]]. Replaced words ['on', 'do', 'doing', 'make'] with ['orn', 'doing', 'done', 'deliver']\n",
      "UNSUCCESSFULL\n",
      "\n",
      "initial q1: How can one start investing in stocks in India?\n",
      "initial q2: How should one start investing in stock market in India?\n",
      "Initial similarity is [[0.91484976]]\n",
      "\n",
      "q1: 'How can one start investing in stocks in India?'\n",
      "q2: 'How should one start investing in stock marketed in India?'\n",
      "Similarity: [[0.6443493]]. Replaced words ['market'] with ['marketed']\n",
      "\n",
      "q1: 'How can one start investing in stocks in India?'\n",
      "q2: 'How should one start investing in stocks marketed in India?'\n",
      "Similarity: [[0.44530824]]. Replaced words ['market', 'stock'] with ['marketed', 'stocks']\n",
      "\n",
      "initial q1: Which is the coolest country in the world?\n",
      "initial q2: What are the coldest countries in the world?\n",
      "Initial similarity is [[0.9202608]]\n",
      "\n",
      "q1: 'Which is the coolest country in the world?'\n",
      "q2: 'What are the colder countries in the world?'\n",
      "Similarity: [[0.7590878]]. Replaced words ['coldest'] with ['colder']\n",
      "\n",
      "q1: 'Which is the coolest country in the world?'\n",
      "q2: 'What are the colder countries onto the world?'\n",
      "Similarity: [[0.33058473]]. Replaced words ['coldest', 'in'] with ['colder', 'onto']\n",
      "\n",
      "initial q1: How can changing 500 and 1000 rupee notes end the black money in India?\n",
      "initial q2: How banning 500 and 1000 rupees note will curb the corruption and black money in India?\n",
      "Initial similarity is [[0.9657263]]\n",
      "\n",
      "q1: 'How can changing 500 and 1000 rupee notes end the black money in India?'\n",
      "q2: 'How banning 500 and 1000 rupees note will curb the bribery and black money in India?'\n",
      "Similarity: [[0.9450501]]. Replaced words ['corruption'] with ['bribery']\n",
      "\n",
      "q1: 'How can changing 500 and 1000 rupee notes end the black money in India?'\n",
      "q2: 'How banning 500 and 1000 rupees note will curb the bribery and black cash in India?'\n",
      "Similarity: [[0.9337968]]. Replaced words ['corruption', 'money'] with ['bribery', 'cash']\n",
      "\n",
      "q1: 'How can changing 500 and 1000 rupee notes end the black money in India?'\n",
      "q2: 'How banning 500 and 1000 rupees note will curb the bribery and black cash onto India?'\n",
      "Similarity: [[0.9293555]]. Replaced words ['corruption', 'money', 'in'] with ['bribery', 'cash', 'onto']\n",
      "\n",
      "q1: 'How can changing 500 and 1000 rupee notes end the black money in India?'\n",
      "q2: 'How banning 500 and 1000 rupees note will curb du bribery and black cash onto India?'\n",
      "Similarity: [[0.9156792]]. Replaced words ['corruption', 'money', 'in', 'the'] with ['bribery', 'cash', 'onto', 'du']\n",
      "\n",
      "q1: 'How can changing 500 and 1000 rupee notes end the black money in India?'\n",
      "q2: 'How banning 500 and 1000 rupees note volition curb du bribery and black cash onto India?'\n",
      "Similarity: [[0.91016877]]. Replaced words ['corruption', 'money', 'in', 'the', 'will'] with ['bribery', 'cash', 'onto', 'du', 'volition']\n",
      "\n",
      "q1: 'How can changing 500 and 1000 rupee notes end the black money in India?'\n",
      "q2: 'How banning 500 and 1000 rupees noting volition curb du bribery and black cash onto India?'\n",
      "Similarity: [[0.9050166]]. Replaced words ['corruption', 'money', 'in', 'the', 'will', 'note'] with ['bribery', 'cash', 'onto', 'du', 'volition', 'noting']\n",
      "\n",
      "q1: 'How can changing 500 and 1000 rupee notes end the black money in India?'\n",
      "q2: 'How banning 500 and 1000 rubles noting volition curb du bribery and black cash onto India?'\n",
      "Similarity: [[0.90382123]]. Replaced words ['corruption', 'money', 'in', 'the', 'will', 'note', 'rupees'] with ['bribery', 'cash', 'onto', 'du', 'volition', 'noting', 'rubles']\n",
      "\n",
      "q1: 'How can changing 500 and 1000 rupee notes end the black money in India?'\n",
      "q2: 'How banning 500 and 1000 rubles noting volition curb du bribery and black money onto India?'\n",
      "Similarity: [[0.9030641]]. Replaced words ['corruption', 'money', 'in', 'the', 'will', 'note', 'rupees', 'cash'] with ['bribery', 'cash', 'onto', 'du', 'volition', 'noting', 'rubles', 'money']\n",
      "UNSUCCESSFULL\n",
      "\n",
      "initial q1: What jobs can someone get with an economics degree?\n",
      "initial q2: What jobs can you get with an economics degree?\n",
      "Initial similarity is [[0.748616]]\n",
      "\n",
      "q1: 'What jobs can someone get with an economics degree?'\n",
      "q2: 'What jobs can vous get with an economics degree?'\n",
      "Similarity: [[0.3389029]]. Replaced words ['you'] with ['vous']\n",
      "\n",
      "initial q1: Why is the FBI investigating Hillary Clinton again?\n",
      "initial q2: Is the FBI “really” investigating Hillary Clinton?\n",
      "Initial similarity is [[0.92714214]]\n",
      "\n",
      "q1: 'Why is the FBI investigating Hillary Clinton again?'\n",
      "q2: 'Is du FBI “ really ” investigating Hillary Clinton?'\n",
      "Similarity: [[0.8550565]]. Replaced words ['the'] with ['du']\n",
      "\n",
      "q1: 'Why is the FBI investigating Hillary Clinton again?'\n",
      "q2: 'Is du FBI “ really ” investigate Hillary Clinton?'\n",
      "Similarity: [[0.8338899]]. Replaced words ['the', 'investigating'] with ['du', 'investigate']\n",
      "\n",
      "q1: 'Why is the FBI investigating Hillary Clinton again?'\n",
      "q2: 'Is du FBI “ truly ” investigate Hillary Clinton?'\n",
      "Similarity: [[0.7898311]]. Replaced words ['the', 'investigating', 'really'] with ['du', 'investigate', 'truly']\n",
      "\n",
      "q1: 'Why is the FBI investigating Hillary Clinton again?'\n",
      "q2: 'Is du FBI “ genuinely ” investigate Hillary Clinton?'\n",
      "Similarity: [[0.7629757]]. Replaced words ['the', 'investigating', 'really', 'truly'] with ['du', 'investigate', 'truly', 'genuinely']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNSUCCESSFULL\n",
      "\n",
      "initial q1: What are some ways to make hair grow faster?\n",
      "initial q2: How can I grow my hair longer fast?\n",
      "Initial similarity is [[0.8593119]]\n",
      "\n",
      "q1: 'What are some ways to make hair grow faster?'\n",
      "q2: 'How kan I grow my hair longer fast?'\n",
      "Similarity: [[0.743599]]. Replaced words ['can'] with ['kan']\n",
      "\n",
      "q1: 'What are some ways to make hair grow faster?'\n",
      "q2: 'How kan I grow my hair longer quick?'\n",
      "Similarity: [[0.56797844]]. Replaced words ['can', 'fast'] with ['kan', 'quick']\n",
      "\n",
      "q1: 'What are some ways to make hair grow faster?'\n",
      "q2: 'How kansas I grow my hair longer quick?'\n",
      "Similarity: [[0.42309883]]. Replaced words ['can', 'fast', 'kan'] with ['kan', 'quick', 'kansas']\n",
      "\n",
      "initial q1: What are the most mysterious things or place on Earth that you know?\n",
      "initial q2: What are the most mysterious things and places on Earth ever discovered?\n",
      "Initial similarity is [[0.9029123]]\n",
      "\n",
      "q1: 'What are the most mysterious things or place on Earth that you know?'\n",
      "q2: 'What are the most mysterious things und places on Earth ever discovered?'\n",
      "Similarity: [[0.53450334]]. Replaced words ['and'] with ['und']\n",
      "\n",
      "q1: 'What are the most mysterious things or place on Earth that you know?'\n",
      "q2: 'What are the anymore mysterious things und places on Earth ever discovered?'\n",
      "Similarity: [[0.21994004]]. Replaced words ['and', 'most'] with ['und', 'anymore']\n",
      "\n",
      "initial q1: What is the most important thing someone has ever said to you?\n",
      "initial q2: What is the most important thing someone has said to you?\n",
      "Initial similarity is [[0.65061337]]\n",
      "\n",
      "q1: 'What is the most important thing someone has ever said to you?'\n",
      "q2: 'What is the most important thing someone has said to vous?'\n",
      "Similarity: [[0.13773498]]. Replaced words ['you'] with ['vous']\n",
      "\n",
      "initial q1: How can noise pollution be controlled?\n",
      "initial q2: How to control noise pollution?\n",
      "Initial similarity is [[0.8395084]]\n",
      "\n",
      "q1: 'How can noise pollution be controlled?'\n",
      "q2: 'How to control noise contamination?'\n",
      "Similarity: [[0.5242417]]. Replaced words ['pollution'] with ['contamination']\n",
      "UNSUCCESSFULL\n",
      "\n",
      "initial q1: Why do some people use Quora when a dictionary or Google could be used instead?\n",
      "initial q2: Why use Quora if you can google?\n",
      "Initial similarity is [[0.7941796]]\n",
      "\n",
      "q1: 'Why do some people use Quora when a dictionary or Google could be used instead?'\n",
      "q2: 'Why use Quora if you can facebook?'\n",
      "Similarity: [[0.67520976]]. Replaced words ['google'] with ['facebook']\n",
      "\n",
      "q1: 'Why do some people use Quora when a dictionary or Google could be used instead?'\n",
      "q2: 'Why use Quora unless you can facebook?'\n",
      "Similarity: [[0.6496822]]. Replaced words ['google', 'if'] with ['facebook', 'unless']\n",
      "\n",
      "q1: 'Why do some people use Quora when a dictionary or Google could be used instead?'\n",
      "q2: 'Why use Quora unless you can twitter?'\n",
      "Similarity: [[0.63204426]]. Replaced words ['google', 'if', 'facebook'] with ['facebook', 'unless', 'twitter']\n",
      "UNSUCCESSFULL\n",
      "\n",
      "initial q1: Is it safe to go to IIT Jammu?\n",
      "initial q2: Is IIT jammu a safe place to study?\n",
      "Initial similarity is [[0.7656177]]\n",
      "\n",
      "q1: 'Is it safe to go to IIT Jammu?'\n",
      "q2: 'Is IIT jammu a safe place pour study?'\n",
      "Similarity: [[0.6907614]]. Replaced words ['to'] with ['pour']\n",
      "\n",
      "q1: 'Is it safe to go to IIT Jammu?'\n",
      "q2: 'Is IIT jammu a safer place pour study?'\n",
      "Similarity: [[0.45415235]]. Replaced words ['to', 'safe'] with ['pour', 'safer']\n",
      "\n",
      "initial q1: I used a fake email and phone number for Snapchat and I forgot my password how can I get it back?\n",
      "initial q2: What do I do if I don't know my Snapchat password or email to it?\n",
      "Initial similarity is [[0.66865486]]\n",
      "\n",
      "q1: 'I used a fake email and phone number for Snapchat and I forgot my password how can I get it back?'\n",
      "q2: 'What do I do if I don't know my Snapchat passwords or email to it?'\n",
      "Similarity: [[0.58228797]]. Replaced words ['password'] with ['passwords']\n",
      "\n",
      "q1: 'I used a fake email and phone number for Snapchat and I forgot my password how can I get it back?'\n",
      "q2: 'What do I do if I don't know my Snapchat passwords or emailed to it?'\n",
      "Similarity: [[0.47353217]]. Replaced words ['password', 'email'] with ['passwords', 'emailed']\n",
      "\n",
      "initial q1: What's the most effective way to cram in college?\n",
      "initial q2: What is the most effective way to cram for an exam?\n",
      "Initial similarity is [[0.6071842]]\n",
      "\n",
      "q1: 'What's the most effective way to cram in college?'\n",
      "q2: 'What is du most effective way to cram for an exam?'\n",
      "Similarity: [[0.22746584]]. Replaced words ['the'] with ['du']\n",
      "\n",
      "initial q1: What are some ways of canceling Primerica online?\n",
      "initial q2: How do you cancel Primerica?\n",
      "Initial similarity is [[0.81296086]]\n",
      "\n",
      "q1: 'What are some ways of canceling Primerica online?'\n",
      "q2: 'How do vous cancel Primerica?'\n",
      "Similarity: [[0.505052]]. Replaced words ['you'] with ['vous']\n",
      "UNSUCCESSFULL\n",
      "\n",
      "initial q1: Why do mothers abandon their children?\n",
      "initial q2: Why would parents abandon their children?\n",
      "Initial similarity is [[0.7848037]]\n",
      "\n",
      "q1: 'Why do mothers abandon their children?'\n",
      "q2: 'Why would parents forgo their children?'\n",
      "Similarity: [[0.49725315]]. Replaced words ['abandon'] with ['forgo']\n",
      "\n",
      "initial q1: Why do people ask questions on Quora that could simply be googled?\n",
      "initial q2: Why are there so many people using Quora to answer questions that can easily be found with a simple Google search?\n",
      "Initial similarity is [[0.92474216]]\n",
      "\n",
      "q1: 'Why do people ask questions on Quora that could simply be googled?'\n",
      "q2: 'Why are there so many people using Quora to answer questions that can easily be found with una simple Google search?'\n",
      "Similarity: [[0.8970788]]. Replaced words ['a'] with ['una']\n",
      "\n",
      "q1: 'Why do people ask questions on Quora that could simply be googled?'\n",
      "q2: 'Why are vi so many people using Quora to answer questions that can easily be found with una simple Google search?'\n",
      "Similarity: [[0.7889005]]. Replaced words ['a', 'there'] with ['una', 'vi']\n",
      "\n",
      "q1: 'Why do people ask questions on Quora that could simply be googled?'\n",
      "q2: 'Why are vi so many people using Quora to answer questions that can readily be found with una simple Google search?'\n",
      "Similarity: [[0.6104295]]. Replaced words ['a', 'there', 'easily'] with ['una', 'vi', 'readily']\n",
      "\n",
      "q1: 'Why do people ask questions on Quora that could simply be googled?'\n",
      "q2: 'Why are vi so many humans using Quora to answer questions that can readily be found with una simple Google search?'\n",
      "Similarity: [[0.5182812]]. Replaced words ['a', 'there', 'easily', 'people'] with ['una', 'vi', 'readily', 'humans']\n",
      "\n",
      "q1: 'Why do people ask questions on Quora that could simply be googled?'\n",
      "q2: 'Why are vi so many beings using Quora to answer questions that can readily be found with una simple Google search?'\n",
      "Similarity: [[0.30896637]]. Replaced words ['a', 'there', 'easily', 'people', 'humans'] with ['una', 'vi', 'readily', 'humans', 'beings']\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-8071a5479c44>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mq2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.6\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0madversarial_white_box_change\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglove\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/query_similarity/NLP/Quora Dataset/adversarial_algos.py\u001b[0m in \u001b[0;36madversarial_white_box_change\u001b[0;34m(q1, q2, model, tp, word_similarity, threshold)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq2_tokenized\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mword_similarity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontains_word\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                 \u001b[0mclosest_word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_similarity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m                 \u001b[0mq2_modified\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq2_tokenized\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0mq2_modified\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclosest_word\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/query_similarity/NLP/Quora Dataset/glove_synonyms.py\u001b[0m in \u001b[0;36mmost_similar\u001b[0;34m(self, word, n)\u001b[0m\n\u001b[1;32m     12\u001b[0m         distances = (np.dot(self.word_vectors, word_vector)\n\u001b[1;32m     13\u001b[0m                        \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_vectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m                        / np.linalg.norm(word_vector))\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0midxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mdistances\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36mnorm\u001b[0;34m(x, ord, axis, keepdims)\u001b[0m\n\u001b[1;32m   2284\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mord\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mord\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2285\u001b[0m             \u001b[0;31m# special case for speedup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2286\u001b[0;31m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2287\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2288\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    q1 = X_test[i, 0]\n",
    "    q2 = X_test[i, 1]\n",
    "    if model.predict_single(q1, q2) > 0.6:\n",
    "        adversarial_white_box_change(q1, q2, model, tp, glove)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
